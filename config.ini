[model]
embedding_dim=40
hidden_dim=100
n_layers=2
dropout=0.3

[preprocessing]
vocab_size=5000
max_pad_len=25

[training]
lr=0.001
batch_size=64
train_test_ratio=0.2
seed=42
epochs=3

[paths]
test_path=../tmp/fake-news/test.csv
train_path=../tmp/fake-news/train.csv
submission_path=../tmp/fake-news/submission.csv
model_path=../tmp/model.pt
vocab_path=../tmp/vocab.pt