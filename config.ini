[model]
embedding_dim=40
hidden_dim=100
n_layers=2
dropout=0.3

[preprocessing]
vocab_size=5000
max_pad_len=25

[training]
lr=0.001
batch_size=64
train_test_ratio=0.2
seed=42
epochs=5